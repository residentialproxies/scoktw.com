<!DOCTYPE html>
<html lang="zh-CN"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <!--title-->
    <title>Top 35 Datasets for ML & AI Models in 2025 | Best Free & Paid Sources</title>

    <!-- SEO Meta description -->
    <meta name="description" content="Discover the top 35 datasets for ML & AI models in 2025. From computer vision and NLP to healthcare and web data, explore the best free and paid datasets to power your machine learning and artificial intelligence projects.">
    <meta name="keywords" content="BrightData, Decodo, Soax, IPRoyal, Webshare, Youproxy, Geonix, Thordata, Toolip, Oxylabs">
    <meta name="author" content="ThemeTags">

    <!-- OG Meta Tags to improve the way the post looks when you share the page on LinkedIn, Facebook, Google+ -->
    <meta property="og:site_name" content="scoktw Proxy IP Blog">

    <!-- website link -->
    <meta property="og:title" content="AI Data Collection Proxies for Model Training">
    <!-- title shown in the actual shared post -->
    <meta property="og:description" content="Discover the top 35 datasets for ML & AI models in 2025. From computer vision and NLP to healthcare and web data, explore the best free and paid datasets to power your machine learning and artificial intelligence projects.">

    <!-- image link, make sure it's jpg -->
    <meta property="og:url" content="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html">
    <!-- where do you want your post to link to -->
    <meta property="og:type" content="article">

    <!--favicon icon-->
    <link rel="icon" href="../assets/img/favicon.ico" type="image/png" sizes="16x16">

    <!--google fonts-->
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;500;600&amp;family=Poppins:wght@400;500;600;700&amp;display=swap" rel="stylesheet">

    <link rel="stylesheet" href="../assets/css/main.css">
    <!-- endbuild -->
    <link rel="stylesheet" href="../assets/css/custom.css">

</head>

<body>


<!--header section start-->
<header id="header" class="header-main headroom">

    <!--main header menu start-->
    <div id="logoAndNav" class="main-header-menu-wrap bg-transparent">
        <div class="container">
            <nav class="js-mega-menu navbar navbar-expand-md header-nav">

                <!--logo start-->
                <a class="navbar-brand" href="index.html"><img src="../assets/img/logo-white-us.png" width="120" alt="logo" class="img-fluid" /></a>
                <!--logo end-->

                <!--responsive toggle button start-->
                <button type="button" class="navbar-toggler btn" aria-expanded="false" aria-controls="navBar" data-toggle="collapse" data-target="#navBar">
                    <span id="hamburgerTrigger">
                        <span class="fas fa-bars"></span>
                    </span>
                </button>
                <!--responsive toggle button end-->

                <!--main menu start-->
                <div id="div_1"></div>
                <!--main menu start-->
                <div id="navBar" class="collapse navbar-collapse">
                    <ul class="navbar-nav ml-auto main-navbar-nav">
                        <li class="nav-item hs-has-mega-menu custom-nav-item" data-max-width="720px" data-position="right">
                            <a id="elementsMegaMenu" class="nav-link custom-nav-link main-link-toggle" href="proxy_ip_china.html" aria-haspopup="true" aria-expanded="false">Global Proxy IP Provider</a>
                            <div class="hs-mega-menu main-sub-menu u-header__mega-menu-position-right-fix--md animated hs-position-right" aria-labelledby="elementsMegaMenu" style="max-width: 600px; display: none;">
                                <div class="mega-menu-wrap">
                                    <span class="sub-menu-title">Global Static Residential Proxy Merchant List(By Region)</span>
                                    <div class="row">
                                        <div class="col-sm-4">
                                            <ul class="sub-menu-nav-group">
                                                <li><a class="nav-link sub-menu-nav-link" href="shared-hosting.html" title="US Proxy IP" rel="bookmark">US Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_china.html" title="China Proxy IP" rel="bookmark">China Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_europe.html" title="EU Proxy IP" rel="bookmark">EU Proxy IP <span class="badge badge-danger ml-2">Hot</span></a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_taiwan.html" title="Taiwan Proxy IP" rel="bookmark">Taiwan Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_hongkong.html" title="Hong Kong Proxy IP" rel="bookmark">Hong Kong Proxy IP</a></li>
                                            </ul>
                                        </div>
                                        <div class="col-sm-4">
                                            <ul class="sub-menu-nav-group">
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_germany.html" title="Germany Proxy IP" rel="bookmark">Germany Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_uk.html" title="UK Proxy IP" rel="bookmark">UK Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_france.html" title="France Proxy IP" rel="bookmark">France Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_korea.html" title="Korea Proxy IP" rel="bookmark">Korea Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_jpan.html" title="Japan Proxy IP" rel="bookmark">Japan Proxy IP <span class="badge badge-danger ml-2">Hot</span></a></li>
                                            </ul>
                                        </div>
                                        <div class="col-sm-4">
                                            <ul class="sub-menu-nav-group">
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_eussia.html" title="Russia Proxy IP" rel="bookmark">Russia Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="spain_static_residential_proxy.html" title="Spanish ISP Proxy" rel="bookmark">Spanish ISP Proxy</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="australia_static_residential_proxy.html" title="Australia Static Proxy IP" rel="bookmark">Australia Static Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_brazil.html" title="Brazil ISP Proxy" rel="bookmark">Brazil Static Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_ip_vietnam.html" title="Vietnam Static Proxy IP" rel="bookmark">Vietnam Static Proxy IP</a></li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                                <div class="secondary-bg">
                                    <div class="u-header__product-banner-content position-relative z-index text-center text-white">
                                        <div class="mb-4">
                                            <h5 class="text-white">Top 12 Best Residential Proxy Service Providers</h5>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <li class="nav-item hs-has-mega-menu custom-nav-item" data-max-width="800px" data-position="right">
                            <a id="elementsMegaMenu" class="nav-link custom-nav-link main-link-toggle" href="proxy_ip_china.html" aria-haspopup="true" aria-expanded="false">Proxy IP type</a>
                            <div class="hs-mega-menu main-sub-menu u-header__mega-menu-position-right-fix--md animated hs-position-right" aria-labelledby="elementsMegaMenu" style="max-width: 600px; display: none;">
                                <div class="mega-menu-wrap">
                                    <span class="sub-menu-title">Pick the Best Proxy Provider (by type)</span>
                                    <div class="row">
                                        <div class="col-sm-4">
                                            <ul class="sub-menu-nav-group">
                                                <li><a class="nav-link sub-menu-nav-link" href="static_residential_proxy_ip.html" title="static residential proxy" rel="bookmark">Best Static Residential Proxy</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="data_center_proxy_ip.html" title="static residential proxy" rel="bookmark">Best Data Center Proxy</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="online_shopping.html" title="Best Sneaker proxies" rel="bookmark">Best Sneaker proxies</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="rotate_proxy_ip.html" title="Best Rotating Proxy" rel="bookmark">Best Rotating Proxy</a></li>
                                                 <li><a class="nav-link sub-menu-nav-link" href="best_exclusive_ipv4_proxy.html" title="Best Sneaker proxies" rel="bookmark">Best IPV4 proxies</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="best_exclusive_socks5_proxy.html" title="Best Rotating Proxy" rel="bookmark">Best socks5 Proxies</a></li>
                                            </ul>
                                        </div>
                                        <div class="col-sm-4">
                                            <ul class="sub-menu-nav-group">
                                                <li><a class="nav-link sub-menu-nav-link" href="tiktok_static_proxy_ip.html" title="Tiktok Static Proxies" rel="bookmark">Tiktok Static IP Proxy</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="Instagram_static_proxy_ip.html" title="Instagram Static Proxies" rel="bookmark">Instagram Static IP Proxy</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="line_static_proxy_ip.html" title="Line Static Proxies" rel="bookmark">Line Static IP Proxy</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="facebook_static_proxy_ip.html" title="Facebook Static Proxies" rel="bookmark">Facebook Static IP Proxy</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="whatsapp_static_proxy_ip.html" title="Whatsapp Static Proxies" rel="bookmark">Whatsapp Static IP Proxy</a></li>
                                            </ul>
                                        </div>
                                            <div class="col-sm-4">
                                            <ul class="sub-menu-nav-group">
                                                <li><a class="nav-link sub-menu-nav-link" href="article_list.html" title="Best Proxy Review Blog" rel="bookmark"><span class="badge badge-primary ml-1">list</span>Best Proxy Review Blog</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="article_list_2.html" title="What is Proxy IP" rel="bookmark"><span class="badge badge-primary ml-1">list</span>What is Proxy IP?</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="article_list_3.html" title="How to use Proxy" rel="bookmark"><span class="badge badge-primary ml-1">list</span>How to use Proxy?</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="cheap_static_proxy.html" title="Cheap Static Proxies" rel="bookmark">Cheap Static Proxy IP</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="monthly_payment_for_long-term_proxy_ip.html" title="long-term static proxies" rel="bookmark">Monthly Static Proxy Providers</a></li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <li class="nav-item hs-has-mega-menu custom-nav-item" data-max-width="600px" data-position="right">
                            <a id="elementsMegaMenu" class="nav-link custom-nav-link main-link-toggle" href="proxy_ip_china.html" aria-haspopup="true" aria-expanded="false">Best Proxy Providers</a>
                            <div class="hs-mega-menu main-sub-menu u-header__mega-menu-position-right-fix--md animated hs-position-right" aria-labelledby="elementsMegaMenu" style="max-width: 600px; display: none;">
                                <div class="mega-menu-wrap">
                                    <span class="sub-menu-title">Proxy IP Provider Review List</span>
                                    <div class="row">
                                        <div class="col-sm-6">
                                            <ul class="sub-menu-nav-group">
                                                <li><a class="nav-link sub-menu-nav-link" href="iproyal_proxy_ip.html" title="Summary of IPRoyal Evaluation" rel="bookmark">IPRoyal review</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="shifter_proxy_ip.html" title="Summary of Shifter Evaluation" rel="bookmark">Shifter review</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="decodo_proxy_ip.html" title="Summary of Decodo Evaluation" rel="bookmark">Decodo review</a></li>
                                            </ul>
                                        </div>
                                        <div class="col-sm-6">
                                            <ul class="sub-menu-nav-group">
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_seller_ip.html" title="Summary of Proxy-seller Evaluation" rel="bookmark">Proxy-seller review</a></li>
                                                <li><a class="nav-link sub-menu-nav-link" href="proxy_cheap_proxy_ip.html" title="Summary of Proxy-Cheap Evaluation" rel="bookmark">Proxy-Cheap review</a></li>
                                            </ul>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </li>
                        <li class="nav-item header-nav-last-item d-flex align-items-center">
                            <a href="article_list.html" class="btn outline-white-btn animated-btn">Article List</a>
                        </li>
                    </ul>

                </div>
                <!--main menu end-->
            </nav>
        </div>
    </div>
    <!--main header menu end-->
</header>
<!--header section end-->
<!--header section end-->

    <div class="main">

        <!--hero section start-->
        <section class="hero-equaubs hero-equal-height section-xl section-header text-white flex-column d-flex justify-content-center" style="background: url(../assets/img/bg-01.jpg)no-repeat center center / cover;">
            <div class="container">
                <div class="row align-items-center justify-content-center">
                    <div class="col-md-9 col-lg-8">
                        <div class="hero-content-left text-white text-center">
                            <h1 class="text-white">Top 35 Datasets for ML & AI Models in 2025 | Best Free & Paid Sources</h1>
                            <p class="lead">Discover the top 35 datasets for ML & AI models in 2025. From computer vision and NLP to healthcare and web data, explore the best free and paid datasets to power your machine learning and artificial intelligence projects.</p>

                        </div>
                    </div>
                </div>
            </div>
        </section>
        <section class="contact-us-promo promo-top pt-100 mt--165">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-md-6 col-sm-6">
                        <div class="card single-promo-card single-promo-hover shadow-sm">
                            <div class="card-body py-5">
                                <div class="post-content ui-sortable">
<p>In the rapidly evolving field of machine learning and artificial intelligence, the quality and diversity of datasets often determine the success of model training and deployment. Whether you are building advanced computer vision systems, natural language processing (NLP) models, recommendation engines, or large-scale generative AI applications, having access to reliable and well-structured datasets is critical.</p>
<p>This article presents a curated list of 35 top datasets for ML & AI models, spanning domains such as image recognition, natural language, bioinformatics, e-commerce, real-time web data, and multimodal AI. The selection includes both open-source datasets that fuel academic research and enterprise-grade commercial datasets designed for large-scale business applications. With these resources, data scientists, researchers, and engineers can accelerate innovation and improve the accuracy, scalability, and generalizability of their AI solutions.</p>


                                    <h2 class="post-title">
                                    <a href="https://get.brightdata.com/ai-data" target="_blank" rel="noopener noreferrer" id="items-center-1">1. Bright Data Datasets</a>
                                    </h2>
                                    <p><strong>Applicable for: </strong>Web Data for ML, Market Intelligence, LLM Training</p>
                                    <p>Bright Data, a leading data-as-a-service provider, recently launched a comprehensive dataset service designed for AI and ML applications. The platform offers ready-to-use structured web data across multiple domains such as e-commerce, real estate, job listings, social media, and financial markets. Unlike traditional static datasets, Bright Data continuously updates its datasets, ensuring freshness and relevance. These datasets are highly valuable for training AI models that depend on real-world, domain-specific data.</p>

                                    <p><strong>Features</strong></p>
                                    <li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Domain-specific datasets: e-commerce, real estate, jobs, social media, finance</li>
                                    <li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Continuously updated and maintained for accuracy</li>
                                    <li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Enterprise-ready with compliance and scalability</li>
                                    <li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Offered as subscription or on-demand service</li>

                                    <div class="col-12 mt-4 text-center">
                                        <a href="https://get.brightdata.com/web-datasets" target="_blank" rel="nofollow noopener" class="btn btn-danger">Get Bright Data Datasets</a>
                                    </div>

                                    <h2 class="post-title">
<a href="https://cocodataset.org/" target="_blank" rel="noopener noreferrer" id="items-center-2">2. COCO (Common Objects in Context)</a>
</h2>
<p><strong>Applicable for: </strong>Object Detection, Segmentation, Scene Understanding</p>
<p>COCO is one of the most popular datasets for computer vision tasks involving object detection, segmentation, and captioning. Unlike traditional datasets, COCO focuses on complex everyday scenes with multiple objects and contextual relationships. Its detailed annotations include object boundaries, keypoints for human pose estimation, and segmentation masks. Because of its high-quality labeling and diversity, COCO has become a standard benchmark for state-of-the-art models like Faster R-CNN, YOLO, and Mask R-CNN.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>330,000+ images with detailed annotations</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>200+ object categories</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Annotations include bounding boxes, segmentation masks, and keypoints</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Supports multiple vision tasks: detection, pose estimation, captioning</li>

<h2 class="post-title">
<a href="https://openai.com/" target="_blank" rel="noopener noreferrer" id="items-center-3">3. OpenAI GPT Training Datasets (Enterprise Access)</a>
</h2>
<p><strong>Applicable for: </strong>Natural Language Processing, Large Language Model Training</p>
<p>While OpenAI’s complete training corpus is proprietary, its large language models such as GPT-3 and GPT-4 are trained on a mixture of licensed, publicly available, and curated datasets at massive scale. These include sources like Common Crawl, Wikipedia, books, and licensed text collections. Organizations seeking enterprise-level access can leverage OpenAI’s API, which encapsulates the knowledge distilled from these datasets. The scale and diversity of the data make it one of the most powerful resources for natural language understanding and generation.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Multi-trillion-token text corpus</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Diverse sources: books, web data, licensed datasets</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Multilingual coverage for global applications</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Available through enterprise-level API access</li>


                                    <h2 class="post-title">
<a href="https://www.kaggle.com/datasets" target="_blank" rel="noopener noreferrer" id="items-center-4">4. Kaggle Datasets</a>
</h2>
<p><strong>Applicable for: </strong>Machine Learning Competitions, Prototyping, Applied AI Research</p>
<p>Kaggle hosts one of the largest open repositories of datasets contributed by its global community of data scientists and machine learning practitioners. The datasets span a wide range of domains including finance, healthcare, natural language processing, and image recognition. One of its biggest advantages is integration with Kaggle Notebooks, allowing users to immediately experiment and build ML models. Kaggle datasets are widely used in hackathons, academic research, and quick prototyping.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Thousands of datasets across industries</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Free and open access</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Integrated with Kaggle Kernels/Notebooks</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Strong community support and active discussions</li>

<h2 class="post-title">
<a href="https://storage.googleapis.com/openimages/web/index.html" target="_blank" rel="noopener noreferrer" id="items-center-5">5. Google Open Images Dataset</a>
</h2>
<p><strong>Applicable for: </strong>Computer Vision, Image Recognition, Multi-Label Classification</p>
<p>The Open Images Dataset by Google is a massive collection of annotated images designed to support large-scale computer vision research. It includes millions of images annotated with image-level labels, object bounding boxes, object segmentation masks, and visual relationships. This diversity allows researchers to build robust vision systems capable of handling complex real-world scenarios. It is widely used to benchmark modern neural network architectures.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>9+ million images with annotations</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>6,000+ categories of objects</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Bounding boxes, segmentation, and relationships provided</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Suitable for training large-scale visual recognition models</li>

<h2 class="post-title">
<a href="https://cocodataset.org/#captions-2015" target="_blank" rel="noopener noreferrer" id="items-center-6">6. COCO Captions Dataset</a>
</h2>
<p><strong>Applicable for: </strong>Image Captioning, Multimodal AI, Vision-Language Models</p>
<p>This dataset extends the original COCO dataset by providing human-annotated captions for each image, making it a cornerstone for multimodal AI research. With five captions per image, it enables models to learn how to generate descriptive natural language outputs from visual inputs. It has been critical in advancing models like image captioning systems, visual question answering (VQA), and more recently, multimodal transformers.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Captions paired with 330,000+ images</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Five unique human-written descriptions per image</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Ideal for vision-language pretraining</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Widely adopted in multimodal AI tasks</li>

<h2 class="post-title">
<a href="https://pubmed.ncbi.nlm.nih.gov/" target="_blank" rel="noopener noreferrer" id="items-center-7">7. PubMed & MIMIC-III</a>
</h2>
<p><strong>Applicable for: </strong>Medical AI, Healthcare NLP, Predictive Analytics</p>
<p>PubMed provides millions of biomedical research articles and abstracts, making it one of the richest sources of scientific text data for healthcare NLP tasks. MIMIC-III, on the other hand, is a large-scale electronic health record dataset containing de-identified clinical data of ICU patients. Together, they empower medical AI research in areas such as disease prediction, drug discovery, and clinical decision support.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>PubMed: Millions of biomedical abstracts and full-text articles</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>MIMIC-III: 60,000+ ICU patient records</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Free access for academic research under proper licensing</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Widely used in medical NLP and healthcare AI</li>

<h2 class="post-title">
<a href="https://laion.ai/blog/laion-5b/" target="_blank" rel="noopener noreferrer" id="items-center-8">8. LAION-5B</a>
</h2>
<p><strong>Applicable for: </strong>Text-to-Image Generation, Multimodal AI, Diffusion Models</p>
<p>LAION-5B is one of the largest open datasets for multimodal research, containing 5 billion image-text pairs collected from the web. It serves as the backbone for many text-to-image generation models, such as Stable Diffusion and other diffusion-based architectures. The dataset is openly available, making it a game-changer for democratizing research in multimodal AI.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>5 billion image-text pairs</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Multilingual captions included</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Open source and freely available</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Powers state-of-the-art generative AI models</li>

<h2 class="post-title">
<a href="https://commoncrawl.org/" target="_blank" rel="noopener noreferrer" id="items-center-9">9. Common Crawl</a>
</h2>
<p><strong>Applicable for: </strong>NLP, Large Language Models, Web-Scale AI Training</p>
<p>Common Crawl is an open-source initiative that provides petabytes of web-crawled data, including raw web pages, metadata, and text extractions. It is widely used as a foundational dataset for training large-scale NLP systems and language models. Because it is updated monthly, researchers and organizations can access a constantly refreshed snapshot of the web, making it one of the most valuable resources for modern AI training pipelines.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Billions of web pages crawled</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Monthly updates with fresh data</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Open and free to access</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Core resource for LLM training and pretraining</li>

<h2 class="post-title">
<a href="https://aws.amazon.com/data-exchange/" target="_blank" rel="noopener noreferrer" id="items-center-10">10. AWS Data Exchange</a>
</h2>
<p><strong>Applicable for: </strong>Enterprise Machine Learning, Data-Driven Applications, Business AI</p>
<p>AWS Data Exchange is a marketplace for subscribing to third-party datasets across industries such as finance, healthcare, geospatial analytics, and marketing. Unlike purely open-source datasets, AWS Data Exchange provides enterprise-grade, high-quality curated data that is ready for use in commercial machine learning and analytics pipelines. Its seamless integration with AWS services makes it particularly attractive for organizations already leveraging the AWS ecosystem.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Curated premium datasets from trusted providers</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Industry-specific data for finance, healthcare, marketing, and more</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Seamless integration with AWS analytics and ML tools</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Subscription-based access with compliance and security guarantees</li>

<h2 class="post-title">
<a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="noopener noreferrer" id="items-center-11">11. Stanford Question Answering Dataset (SQuAD)</a>
</h2>
<p><strong>Applicable for: </strong>Natural Language Processing, Question Answering Systems</p>
<p>SQuAD is a large-scale dataset built for machine comprehension of text. It consists of passages from Wikipedia paired with over 100,000 crowd-sourced question–answer pairs. Models trained on SQuAD learn to extract answers directly from context passages, making it an essential benchmark for evaluating the reading comprehension ability of NLP models. It has been pivotal in the development of transformer architectures like BERT.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>100,000+ question–answer pairs</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Based on real-world Wikipedia articles</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Widely used benchmark for NLP research</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Supports extractive and abstractive QA tasks</li>

<h2 class="post-title">
<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noopener noreferrer" id="items-center-12">12. MNIST Handwritten Digits</a>
</h2>
<p><strong>Applicable for: </strong>Computer Vision, Image Classification, Deep Learning Basics</p>
<p>MNIST is one of the most famous datasets for machine learning beginners. It consists of 70,000 grayscale images of handwritten digits (0–9), each standardized to 28×28 pixels. Despite its simplicity, MNIST has been used for decades to test new machine learning techniques and remains a staple in tutorials, benchmarks, and research papers.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>70,000 labeled images of handwritten digits</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Standard 28×28 pixel format</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Excellent for benchmarking classification algorithms</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Common starting point for deep learning projects</li>

<h2 class="post-title">
<a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="noopener noreferrer" id="items-center-13">13. CIFAR-10 / CIFAR-100</a>
</h2>
<p><strong>Applicable for: </strong>Computer Vision, Image Classification</p>
<p>The CIFAR datasets are small-scale image collections used for machine learning research. CIFAR-10 contains 60,000 images across 10 classes, while CIFAR-100 expands this to 100 categories. Both are widely used to benchmark neural network architectures because of their compact size and diverse visual classes.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>CIFAR-10: 10 classes, 60,000 images</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>CIFAR-100: 100 classes, 60,000 images</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>32×32 pixel RGB images</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Popular benchmark for CNN research</li>

<h2 class="post-title">
<a href="https://www.yelp.com/dataset" target="_blank" rel="noopener noreferrer" id="items-center-14">14. Yelp Open Dataset</a>
</h2>
<p><strong>Applicable for: </strong>Sentiment Analysis, NLP, Recommender Systems</p>
<p>The Yelp Open Dataset is a large-scale collection of reviews, ratings, and business metadata made available by Yelp for academic and non-commercial use. It is highly valuable for training sentiment analysis models, recommendation engines, and text classification algorithms, as it combines natural language with structured business attributes.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Millions of reviews and user ratings</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Includes business, check-in, and tip data</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Real-world text data for NLP tasks</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Useful for recommendation and sentiment modeling</li>

<h2 class="post-title">
<a href="https://dumps.wikimedia.org/" target="_blank" rel="noopener noreferrer" id="items-center-15">15. Wikipedia Dumps</a>
</h2>
<p><strong>Applicable for: </strong>NLP, Knowledge Graphs, Pretraining Large Language Models</p>
<p>Wikipedia provides periodic full dumps of its entire content in multiple languages. These dumps serve as one of the most reliable and clean sources of text data for NLP, powering tasks like question answering, knowledge extraction, and LLM pretraining. Its structured nature and wide coverage of domains make it indispensable in AI research.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Multilingual data across hundreds of languages</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Regularly updated and freely available</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>High-quality encyclopedic knowledge base</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Widely used in LLM pretraining</li>

<h2 class="post-title">
<a href="http://www.cvlibs.net/datasets/kitti/" target="_blank" rel="noopener noreferrer" id="items-center-16">16. KITTI Dataset</a>
</h2>
<p><strong>Applicable for: </strong>Autonomous Driving, Computer Vision, 3D Object Detection</p>
<p>The KITTI dataset is a comprehensive benchmark suite for autonomous driving research. It includes stereo camera images, 3D LiDAR point clouds, and GPS/IMU data, covering multiple real-world driving scenarios. KITTI has been foundational for training and benchmarking self-driving car perception systems.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>6 hours of driving data captured in real-world traffic</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Stereo images, 3D bounding boxes, and LiDAR scans</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Benchmarks for multiple tasks: detection, tracking, depth estimation</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Standard dataset for autonomous driving research</li>

<h2 class="post-title">
<a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank" rel="noopener noreferrer" id="items-center-17">17. Fashion-MNIST</a>
</h2>
<p><strong>Applicable for: </strong>Image Classification, Computer Vision</p>
<p>Fashion-MNIST was introduced as a modern alternative to MNIST, containing grayscale images of fashion items such as shirts, shoes, and bags. It has the same format as MNIST (28×28 pixel grayscale images) but presents a more challenging classification task, making it popular for benchmarking computer vision algorithms.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>70,000 images of 10 fashion categories</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Same format as MNIST for easy integration</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Provides more complexity than digit classification</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Widely used in tutorials and educational research</li>

<h2 class="post-title">
<a href="https://ai.google.com/research/NaturalQuestions/" target="_blank" rel="noopener noreferrer" id="items-center-18">18. Google’s Natural Questions (NQ)</a>
</h2>
<p><strong>Applicable for: </strong>NLP, Question Answering, Information Retrieval</p>
<p>Natural Questions (NQ) is a benchmark dataset created by Google that provides real anonymized queries from search users along with corresponding Wikipedia passages. It challenges models to perform both retrieval and reasoning, making it a more realistic dataset for question answering systems compared to synthetic datasets.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Over 300,000 questions with human annotations</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Pairs user queries with long and short answers</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Real-world queries sourced from Google Search</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Supports both extractive and generative QA tasks</li>

<h2 class="post-title">
<a href="https://archive.ics.uci.edu/ml/index.php" target="_blank" rel="noopener noreferrer" id="items-center-19">19. UCI Machine Learning Repository</a>
</h2>
<p><strong>Applicable for: </strong>General Machine Learning, Education, Prototyping</p>
<p>The UCI Machine Learning Repository is one of the oldest and most widely used resources for ML datasets. It contains hundreds of datasets across a variety of domains such as classification, regression, and clustering. Researchers, educators, and students frequently use UCI datasets for teaching, prototyping, and benchmarking algorithms.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>500+ datasets across multiple tasks</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Covers text, numeric, categorical, and mixed data types</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Open access and community-supported</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Popular for academic research and teaching</li>

<h2 class="post-title">
<a href="https://www.cs.cmu.edu/~enron/" target="_blank" rel="noopener noreferrer" id="items-center-20">20. Enron Email Dataset</a>
</h2>
<p><strong>Applicable for: </strong>NLP, Email Classification, Spam Detection</p>
<p>The Enron Email Dataset contains around 500,000 real-world email messages from the now-defunct Enron Corporation. It has become a standard dataset for research in text mining, communication analysis, and spam detection. Because of its authentic corporate communication style, it provides unique challenges for natural language understanding.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>500,000+ real-world corporate emails</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Includes sender, recipient, timestamp, and content</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Common benchmark for spam filtering and classification</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Valuable for studying social network interactions</li>


<h2 class="post-title">
<a href="https://gluebenchmark.com/" target="_blank" rel="noopener noreferrer" id="items-center-21">21. GLUE Benchmark (General Language Understanding Evaluation)</a>
</h2>
<p><strong>Applicable for: </strong>NLP, Sentence Classification, Language Understanding</p>
<p>GLUE is a benchmark suite designed to evaluate natural language understanding models across a diverse set of tasks, including sentiment analysis, textual entailment, and question answering. It has become the gold standard for testing transformer-based models like BERT, RoBERTa, and GPT. GLUE provides a unified framework that pushes models toward achieving general-purpose NLP capabilities.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>9 different NLP tasks in one benchmark</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Widely used for pretraining evaluation</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Encourages multi-task learning approaches</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Leaderboards track state-of-the-art models</li>

<h2 class="post-title">
<a href="https://super.gluebenchmark.com/" target="_blank" rel="noopener noreferrer" id="items-center-22">22. SuperGLUE</a>
</h2>
<p><strong>Applicable for: </strong>NLP, Advanced Language Understanding</p>
<p>SuperGLUE was introduced as a harder successor to GLUE, offering more challenging tasks designed to test reasoning, commonsense understanding, and coreference resolution. It is particularly aimed at pushing beyond surface-level text classification, serving as a benchmark for the latest and most advanced NLP models.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Multiple challenging tasks for deep language understanding</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Includes reading comprehension, reasoning, and coreference</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Harder than GLUE, pushing SOTA models further</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Essential for evaluating transformer-based NLP architectures</li>

<h2 class="post-title">
<a href="https://catalog.ldc.upenn.edu/LDC93S1" target="_blank" rel="noopener noreferrer" id="items-center-130">23. TIMIT Acoustic-Phonetic Continuous Speech Corpus</a>
</h2>
<p><strong>Applicable for: </strong>Speech Recognition, Audio Processing</p>
<p>TIMIT is a classic dataset for speech recognition research. It consists of recordings from hundreds of speakers across different dialects of American English, each reading a carefully curated set of sentences. The dataset includes time-aligned phonetic and word transcriptions, making it indispensable for phoneme recognition and acoustic modeling.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>6,300 utterances from 630 speakers</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Time-aligned phonetic and word transcripts</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Covers 8 major American English dialects</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Standard dataset for speech recognition</li>

<h2 class="post-title">
<a href="http://www.openslr.org/12/" target="_blank" rel="noopener noreferrer" id="items-center-131">24. LibriSpeech</a>
</h2>
<p><strong>Applicable for: </strong>Automatic Speech Recognition (ASR), NLP + Audio</p>
<p>LibriSpeech is a large-scale speech dataset derived from public domain audiobooks read by volunteers. It is widely used for training automatic speech recognition (ASR) systems. The dataset offers both clean and noisy versions of recordings, enabling robust model development. It has been a cornerstone for modern ASR benchmarks.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>1,000 hours of speech data</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Derived from audiobooks (LibriVox project)</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Includes clean and noisy subsets</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Widely used for training end-to-end ASR models</li>

<h2 class="post-title">
<a href="https://waymo.com/open/" target="_blank" rel="noopener noreferrer" id="items-center-132">25. Waymo Open Dataset</a>
</h2>
<p><strong>Applicable for: </strong>Autonomous Driving, 3D Perception, LiDAR</p>
<p>Waymo Open Dataset is one of the most comprehensive autonomous driving datasets available to the public. It includes high-resolution sensor data collected from Waymo’s self-driving vehicles, including LiDAR, camera feeds, and detailed annotations for 3D detection and tracking. This dataset is critical for advancing safe and robust autonomous navigation systems.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Millions of 3D annotated objects</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Multi-sensor recordings: LiDAR, radar, cameras</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Real-world urban driving scenarios</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Benchmark for autonomous vehicle research</li>

<h2 class="post-title">
<a href="http://vision.imar.ro/human3.6m/" target="_blank" rel="noopener noreferrer" id="items-center-133">26. Human3.6M</a>
</h2>
<p><strong>Applicable for: </strong>Human Pose Estimation, Motion Capture, 3D Vision</p>
<p>Human3.6M is one of the largest datasets for human pose estimation and action recognition. It contains millions of 3D human poses captured using motion capture technology, along with corresponding video recordings. It is widely used for training deep models in activity recognition, AR/VR, and robotics.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>3.6 million 3D human poses</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>11 professional actors performing diverse actions</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Multi-camera synchronized recordings</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Standard dataset for human motion understanding</li>

<h2 class="post-title">
<a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank" rel="noopener noreferrer" id="items-center-134">27. CelebA (CelebFaces Attributes Dataset)</a>
</h2>
<p><strong>Applicable for: </strong>Facial Recognition, Attribute Classification, GAN Training</p>
<p>CelebA is a large-scale face attributes dataset containing over 200,000 celebrity images with detailed annotations for 40 different attributes such as gender, age, and facial expressions. It is widely used in facial recognition, generative adversarial networks (GANs), and fairness/bias research in AI.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>200,000+ celebrity images</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>40 labeled facial attributes per image</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Diverse backgrounds, poses, and lighting conditions</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Popular for GANs and facial recognition</li>

<h2 class="post-title">
<a href="https://nlp.stanford.edu/sentiment/" target="_blank" rel="noopener noreferrer" id="items-center-135">28. Stanford Sentiment Treebank (SST)</a>
</h2>
<p><strong>Applicable for: </strong>Sentiment Analysis, NLP, Text Classification</p>
<p>The Stanford Sentiment Treebank is a richly annotated sentiment analysis dataset that goes beyond simple positive/negative classification. It includes fine-grained sentiment labels for phrases within sentences, enabling hierarchical sentiment modeling. It has been key for developing sentiment-aware NLP models.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>215,000+ phrases from movie reviews</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Fine-grained sentiment annotations (5 levels)</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Enables hierarchical sentiment classification</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Standard benchmark for NLP sentiment analysis</li>


<h2 class="post-title">
<a href="http://www.image-net.org/" target="_blank" rel="noopener noreferrer" id="items-center-29">29. ImageNet</a>
</h2>
<p><strong>Applicable for: </strong>Computer Vision, Deep Learning, Image Classification</p>
<p>ImageNet is one of the most influential datasets in the history of artificial intelligence. It consists of over 14 million images that are carefully labeled across thousands of object categories. This dataset was a driving force behind the deep learning revolution, particularly after the success of AlexNet in the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC). Researchers and developers use ImageNet not only for training powerful image classifiers but also as a benchmark for evaluating new architectures in computer vision.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Over 14 million annotated images</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>20,000+ categories with hierarchical labeling</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Widely adopted benchmark for visual recognition tasks</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Foundation for transfer learning in deep learning</li>

<h2 class="post-title">
<a href="https://www.alphafold.ebi.ac.uk/" target="_blank" rel="noopener noreferrer" id="items-center-30">30. DeepMind’s AlphaFold Protein Structure Database</a>
</h2>
<p><strong>Applicable for: </strong>Bioinformatics, Healthcare AI, Protein Folding Prediction</p>
<p>The AlphaFold Protein Structure Database, developed by DeepMind in collaboration with EMBL-EBI, provides predicted 3D structures of proteins at an unprecedented scale. It covers virtually every protein sequence known to science, revolutionizing biology and drug discovery by offering accurate protein folding predictions that were once a grand challenge.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>200+ million protein structures predicted</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Free and open to the global scientific community</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Breakthrough resource for drug design and biology</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>High accuracy predictions validated against lab results</li>



<h2 class="post-title">
<a href="https://image-net.org/download-images" target="_blank" rel="noopener noreferrer" id="items-center-136">31. ImageNet-21K</a>
</h2>
<p><strong>Applicable for: </strong>Computer Vision, Transfer Learning, Pretraining Large Models</p>
<p>ImageNet-21K is an extended version of the original ImageNet dataset, offering over 14 million images across 21,000 categories. It is widely used for pretraining large-scale vision models before fine-tuning on specific tasks. Its massive category coverage makes it more comprehensive than the standard ImageNet-1K, helping models learn generalized visual features.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>14 million+ images</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>21,000+ object categories</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Used in training large-scale vision transformers (ViTs)</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Critical for transfer learning in CV research</li>

<h2 class="post-title">
<a href="https://nijianmo.github.io/amazon/index.html" target="_blank" rel="noopener noreferrer" id="items-center-137">32. Amazon Product Dataset (Amazon Reviews)</a>
</h2>
<p><strong>Applicable for: </strong>NLP, Recommender Systems, Sentiment Analysis</p>
<p>The Amazon Product Dataset is one of the most widely used resources for recommendation engines and sentiment analysis. It contains hundreds of millions of customer reviews, product metadata, and ratings across diverse categories. Researchers rely on this dataset to train models for personalized recommendation systems, sentiment classification, and e-commerce analytics.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>200+ million reviews across product categories</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Includes text reviews, star ratings, and product metadata</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Rich resource for recommender systems</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Free for academic and research purposes</li>

<h2 class="post-title">
<a href="https://huggingface.co/datasets" target="_blank" rel="noopener noreferrer" id="items-center-138">33. Hugging Face Datasets Hub</a>
</h2>
<p><strong>Applicable for: </strong>NLP, Computer Vision, Speech, Multimodal AI</p>
<p>The Hugging Face Datasets Hub is a collaborative platform that hosts thousands of datasets for machine learning across domains including NLP, computer vision, and audio. It is tightly integrated with the Hugging Face ecosystem, allowing researchers to load datasets directly into transformers and other ML pipelines with just a few lines of code. Its community-driven nature ensures constant growth and diversity.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>10,000+ datasets available in multiple domains</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Simple integration with Hugging Face Transformers</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Active community contributions and updates</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Supports text, image, audio, and multimodal ML tasks</li>

<h2 class="post-title">
<a href="https://www.cityscapes-dataset.com/" target="_blank" rel="noopener noreferrer" id="items-center-34">34. Cityscapes Dataset</a>
</h2>
<p><strong>Applicable for: </strong>Semantic Segmentation, Urban Scene Understanding</p>
<p>Cityscapes focuses on understanding urban street scenes, making it one of the most widely used datasets in computer vision for semantic segmentation tasks. It contains high-resolution images taken in 50 European cities, with fine-grained pixel-level annotations for road scenes. Researchers rely on Cityscapes to benchmark semantic segmentation models.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>5,000 finely annotated images</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Pixel-level semantic segmentation labels</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Focused on urban driving environments</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Standard dataset for segmentation tasks</li>

<h2 class="post-title">
<a href="http://www.statmt.org/wmt/" target="_blank" rel="noopener noreferrer" id="items-center-35">35. WMT (Workshop on Machine Translation) Datasets</a>
</h2>
<p><strong>Applicable for: </strong>Machine Translation, Multilingual NLP</p>
<p>WMT datasets are released annually as part of the Workshop on Machine Translation. They provide parallel corpora across multiple languages and domains, fueling advancements in neural machine translation systems. These datasets are widely used to train models like Google Translate and multilingual transformers.</p>

<p><strong>Features</strong></p>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Parallel corpora across dozens of languages</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Updated yearly with new domains and text sources</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Core benchmark for machine translation systems</li>
<li class="py-1"><span class="ti-control-forward mr-2 color-primary"></span>Supports both supervised and unsupervised MT research</li>


                                <div class="section-heading mb-5" style="margin-top: 50px;">
                                    <h2 class="post-title">Conclusion</h2>
                                    <p>Datasets are the foundation of machine learning and AI innovation. From classic benchmarks like ImageNet and COCO to enterprise-grade services such as Bright Data Datasets, the availability of high-quality, domain-specific data empowers researchers and developers to build models that are more accurate, robust, and production-ready.</p>
                                    <p>As AI continues to expand into new industries—from healthcare to finance, and from e-commerce to social media—having the right dataset is more important than ever. By leveraging these 35 curated datasets, you can not only accelerate model development but also ensure your AI systems remain competitive and future-proof in 2025 and beyond.
                                    </p>
                                </div>
                                <div class="post-footer">
                                    <div class="post-tags">
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Bright Data">Bright Data</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Kaggle">Kaggle</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Google Open Images">Google Open Images</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="COCO">COCO</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="OpenAI GPT Training">OpenAI GPT</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="PubMed">PubMed</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="MIMIC-III">MIMIC-III</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="LAION-5B">LAION-5B</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Common Crawl">Common Crawl</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="AWS Data Exchange">AWS Data Exchange</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="SQuAD">SQuAD</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="MNIST">MNIST</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="CIFAR">CIFAR</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Yelp Open Dataset">Yelp Open Dataset</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Wikipedia Dumps">Wikipedia Dumps</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Enron Email Dataset">Enron Email Dataset</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="KITTI">KITTI</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Fashion-MNIST">Fashion-MNIST</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Google Natural Questions">Google Natural Questions</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="UCI Machine Learning Repository">UCI Machine Learning Repository</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="GLUE Benchmark">GLUE Benchmark</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="SuperGLUE">SuperGLUE</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="TIMIT">TIMIT</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="LibriSpeech">LibriSpeech</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Waymo Open Dataset">Waymo Open Dataset</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Human3.6M">Human3.6M</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="CelebA">CelebA</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Stanford Sentiment Treebank">Stanford Sentiment Treebank</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="ImageNet-21K">ImageNet-21K</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Amazon Product Dataset">Amazon Product Dataset</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Hugging Face Datasets Hub">Hugging Face Datasets Hub</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="Cityscapes Dataset">Cityscapes Dataset</a>
                                        <a href="https://scoktw.com/us/best-datasets-for-ml-and-ai-models.html" title="WMT Datasets">WMT Datasets</a>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </section>
        <!--hero section end-->
        <!--faq section start-->
        <div id="faq" class="ptb-100 ">
            <div class="container">
                <div class="row">
                    <div class="col-md-12 col-lg-12">
                        <div id="accordion-one" class="accordion accordion-faq">
                            <div class="card mb-0">
                                <a class="card-header collapsed" data-toggle="collapse" href="#collapseOne">
                                    <h6 class="mb-0 d-inline-block">What makes a dataset suitable for machine learning and AI models?
                                    </h6>
                                </a>
                                <div id="collapseOne" class="collapse" data-parent="#accordion-one">
                                    <div class="card-body">
                                        <p>A computer program or algorithm trained on data to perform certain tasks. Therefore, it will recognize certain patterns, make predictions, and even generate relevant content.
                                        </p>
                                    </div>
                                </div>
                            </div>
                            <div class="card mb-0">
                                <a class="card-header collapsed" data-toggle="collapse" href="#collapseTwo">
                                    <h6 class="mb-0 d-inline-block">Are open-source datasets enough for building production-level AI models?</h6>
                                </a>
                                <div id="collapseTwo" class="collapse" data-parent="#accordion-one">
                                    <div class="card-body">
                                        <p>You need to consider the proxy types they offer, proxy pool size, speed, reliability, cost, reputation, project goals, proxy anonymity level, and use case.
                                        </p>
                                    </div>
                                </div>
                            </div>
                            <div class="card mb-0">
                                <a class="card-header collapsed" data-toggle="collapse" href="#collapseThree">
                                    <h6 class="mb-0 d-inline-block">How often should datasets be updated for AI projects?
                                    </h6>
                                </a>
                                <div id="collapseThree" class="collapse" data-parent="#accordion-one">
                                    <div class="card-body">
                                        <p>The best proxy for data collection is residential proxies, due to their anonymity level; however, you can also consider datacenter proxies, mobile proxies, and ISP proxies.
                                        </p>
                                    </div>
                                </div>
                            </div>
                            <div class="card mb-0">
                                <a class="card-header collapsed" data-toggle="collapse" href="#collapseThree">
                                    <h6 class="mb-0 d-inline-block">Can I use these datasets to train large language models (LLMs)?
                                    </h6>
                                </a>
                                <div id="collapseThree" class="collapse" data-parent="#accordion-one">
                                    <div class="card-body">
                                        <p>Some datasets, such as Common Crawl, Hugging Face Datasets Hub, and Bright Data web datasets, are suitable for LLM training. However, training at LLM scale typically requires significant infrastructure and a combination of multiple large datasets.
                                        </p>
                                    </div>
                                </div>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>


        <!--faq section end-->


        <!--faq section start-->



        <!--faq section end-->



    </div>
    <div id="faq" class="ptb-100">
        <div class="container">
            <div class="row">
                <div class="col-md-12 col-lg-12">
                    <div id="accordion-one" class="accordion accordion-faq">
                        <h2>Related Reading</h2>
                        <div class="row">
                            <div class="col-lg-4 col-md-6 col-sm-6">
                                <div class="card single-promo-card single-promo-hover text-center shadow-sm">
                                    <div class="card-body py-5">
                                        <a href="static_ip.html">
                                            <div class="pb-2">
                                                <img src="../assets/img/iproyal_1580.png" width="320" class="img-fluid">
                                            </div>
                                            <div>
                                                <h5 class="mb-0">The difference between static IP and dynamic IP</h5>
                                                <p class="text-muted mb-0" style="font-size: 0.9rem;">The Internet and your network are linked together by Internet Protocol (IP) addresses. There are two types of IP addresses: static IP and dynamic IP. This article examines the main characteristics of static IPs and dynamic IP addresses so you can better decide which one to use.</p>
                                            </div>
                                        </a>
                                    </div>
                                </div>
                            </div>
                            <div class="col-lg-4 col-md-6 col-sm-6">
                                <div class="card single-promo-card single-promo-hover text-center shadow-sm">
                                    <div class="card-body py-5">
                                        <a href="data_center_and_residential.html">
                                            <div class="pb-2">
                                                <img src="../assets/img/iproyal_1520.png" width="320" class="img-fluid">
                                            </div>
                                            <div>
                                                <h5 class="mb-0">The difference between data center IP and residential IP</h5>
                                                <p class="text-muted mb-0" style="font-size: 0.9rem;">The main difference between data center IP and residential IP lies in their usage scenarios and distribution methods, the purposes and network conditions they serve, and the differences in bandwidth and latency. Among them, the data center IP provides more stable,</p>
                                            </div>
                                        </a>
                                    </div>
                                </div>
                            </div>
                            <div class="col-lg-4 col-md-6 col-sm-6">
                                <div class="card single-promo-card single-promo-hover text-center shadow-sm">
                                    <div class="card-body py-5">
                                        <a href="static_iphone_settings_socks5.html">
                                            <div class="pb-2">
                                                <img src="../assets/img/iproyal_1530.png" width="320" class="img-fluid">
                                            </div>
                                            <div>
                                                <h5 class="mb-0">CentOS7 builds Socks5 proxy server</h5>
                                                <p class="text-muted mb-0" style="font-size: 0.9rem;">Socks Proxy (Socket Secure) is a network protocol designed to allow clients to connect to servers over the Internet. It communicates via Transmission Control Protocol (TCP) or User Datagram Protocol (UDP)</p>
                                            </div>
                                        </a>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
<!--footer section start-->
<footer class="footer-section">
    <!--footer top start-->
    <div class="footer-top gradient-bg">
        <div class="container">
            <div class="row">
                <div class="col-md-3">
                    <div class="row footer-top-wrap">
                        <div class="col-12">
                            <div class="footer-nav-wrap text-white">
                                <h4 class="text-white">Sponsor</h4>
                                <ul class="list-inline security-icon-list">
                                    <li class="list-inline-item">
                                        <a href="../affiliates.html?aff=1111" target="_blank" rel="nofollow noopener"><img src="../assets/img/bright-data-logo.jpg" width="110" alt="security" class="img-fluid" /></a>
                                    </li>
                                    <li class="list-inline-item">
                                        <a href="../affiliates.html?aff=2222" target="_blank" rel="nofollow noopener"><img src="../assets/img/soax-logo.jpg" width="110" alt="security" class="img-fluid" /></a>
                                    </li>
                                    <li class="list-inline-item">
                                        <a href="../affiliates.html?aff=3333" target="_blank" rel="nofollow noopener"><img src="../assets/img/proxy-seller-logo.jpg" width="110" alt="security" class="img-fluid" /></a>
                                    </li>
                                    <li class="list-inline-item">
                                        <a href="../affiliates.html?aff=4444" target="_blank" rel="nofollow noopener"><img src="../assets/img/netnut-logo.jpg" width="110" alt="security" class="img-fluid" /></a>
                                    </li>
                                    <li class="list-inline-item">
                                        <a href="../affiliates.html?aff=5555" target="_blank" rel="nofollow noopener"><img src="../assets/img/decodo-logo.jpg" width="110" alt="security" class="img-fluid" /></a>
                                    </li>
                                    <li class="list-inline-item">
                                        <a href="../affiliates.html?aff=6666" target="_blank" rel="nofollow noopener"><img src="../assets/img/proxy-ipv4-logo.jpg" width="110" alt="security" class="img-fluid" /></a>
                                    </li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-md-9">
                    <div class="row footer-top-wrap">
                        <div class="col-md-4 col-sm-6">
                            <div class="footer-nav-wrap text-white">
                                <h4 class="text-white">Blog</h4>
                                <ul class="nav flex-column">
                                    <li class="nav-item">
                                        <a class="nav-link" href="shared-hosting.html">Best US Proxy IP</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="proxy_ip_china.html">Best China Proxy IP</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="proxy_ip_europe.html">Best European Proxy IP</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="proxy_ip_taiwan.html">Best Taiwan Proxy IP</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="proxy_ip_uk.html">Best UK Proxy IP</a>
                                    </li>
                                </ul>
                            </div>
                        </div>
                        <div class="col-md-4 col-sm-6">
                            <div class="footer-nav-wrap text-white">
                                <h4 class="text-white">Popular blog</h4>
                                <ul class="nav flex-column">
                                    <li class="nav-item">
                                        <a class="nav-link" href="what_is_a_proxy_ip.html">What is proxy IP?</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="fingerprint_browser.html">Fingerprint browsers</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="static_ip.html">Static IP vs. Dynamic IP</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="between_socks5_proxy_and_https_proxy.html">Socks5 proxy vs. HTTP(S) proxy</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="data_center_and_residential.html">Data center IP vs. Residential IP</a>
                                    </li>
                                </ul>
                            </div>
                        </div>
                        <div class="col-md-4 col-sm-6">
                            <div class="footer-nav-wrap text-white">
                                <h4 class="text-white">Types of Proxies</h4>
                                <ul class="nav flex-column">
                                    <li class="nav-item">
                                        <a class="nav-link" href="static_residential_proxy_ip.html">Best Static Residential Proxies</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="data_center_proxy_ip.html">Best Data Center Proxies</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="rotate_proxy_ip.html">Best Rotating Proxies</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="best_exclusive_ipv4_proxy.html">Best Exclusive IPv4 Proxies</a>
                                    </li>
                                    <li class="nav-item">
                                        <a class="nav-link" href="best_exclusive_socks5_proxy.html">Best Socks5 Proxies</a>
                                    </li>
                                </ul>
                            </div>
                        </div>
    
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!--footer top end-->

            <div class="row align-items-center justify-content-between scroll-us-top scroll-us-to-target open">
            <div class="col-lg-12 col-md-12 col-12">
                <div class="card popular-price text-center single-pricing-pack">
                    <div class="pt-5">
                        <h5 class="mb-0">TOP <u class="res_u">10</u></h5>
                    </div>
                    <div class="single-partner-wrap card-bottom-line white-bg shadow-sm rounded text-center p-2 mt-4">
                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-1')" class="view-details-link">Bright Data Datasets<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-2')" class="view-details-link">COCO<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-3')" class="view-details-link">OpenAI GPT Training Datasets<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-4')" class="view-details-link">Kaggle Datasets<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-5')" class="view-details-link">Google Open Images Dataset<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-6')" class="view-details-link">COCO Captions Dataset<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-7')" class="view-details-link">PubMed & MIMIC-III<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-8')" class="view-details-link">LAION-5B<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-9')" class="view-details-link">Common Crawl<span class="ti-angle-right"></span></a>
                        </div>

                        <div class="partner-info">
                            <a href="javascript:;" onclick="goDiv('items-center-10')" class="view-details-link">AWS Data Exchange<span class="ti-angle-right"></span></a>
                        </div>                        
                    </div>
                </div>
            </div>
        </div>
        
        <!--footer copyright start-->
        <div class="footer-bottom gray-light-bg py-3">
            <div class="container">
                <div class="row align-items-center justify-content-between">
                    <div class="col-md-5 col-lg-5">
                        <p class="copyright-text pb-0 mb-0">© Copyright 2025 scoktw.com. All rights reserved by 
                            <a href="https://scoktw.com" target="_blank">Proxy IP
                            </a>
                        </p>
                    </div>

                </div>
            </div>
        </div>
        <!--footer copyright end-->
    </footer>
    <!--footer section end-->
    <!--bottom to top button start-->
    <button class="scroll-top scroll-to-target" data-target="html">
        <span class="ti-rocket"></span>
    </button>
    <!--bottom to top button end-->
    <script type="text/javascript">
        var div_child = '<ul class="navbar-nav ml-auto main-navbar-nav"> <li class="nav-item hs-has-sub-menu custom-nav-item"> <a id="pagesMegaMenu" class="nav-link custom-nav-link main-link-toggle" href="./article_list.html" aria-haspopup="true" aria-expanded="false" aria-labelledby="pagesSubMenu"> <img src="../assets/img/svg/us.svg" alt="com" width="30" style="margin-right: 7px;" class="img-fluid">English</a> <ul id="pagesSubMenu" class="hs-sub-menu main-sub-menu animated" aria-labelledby="pagesMegaMenu" style="min-width: 160px; display: none;"> <li class="nav-item submenu-item"> <a class="nav-link sub-menu-nav-link" href="../hk/article_list.html"> <img src="../assets/img/svg/hk.svg" alt="com" width="30" style="margin-right: 7px;" class="img-fluid">繁体</a> </li> <li class="nav-item submenu-item"> <a class="nav-link sub-menu-nav-link" href="../article_list.html"> <img src="../assets/img/svg/cn.svg" alt="com" width="30" style="margin-right: 7px;" class="img-fluid">中文</a> </li> <li class="nav-item submenu-item"> <a class="nav-link sub-menu-nav-link" href="https://scoktw.com/ru/article_list.html"> <img src="../assets/img/svg/ru.svg" alt="com" width="30" style="margin-right: 7px;" class="img-fluid">Русский</a> </li> </ul> </li> </ul>'
        var c = document.getElementById('div_1');
        c.innerHTML += div_child;
 function goDiv(div) {
var a = $("#" + div).offset().top;
$("html,body").animate({
scrollTop: a
}, 'slow');
}
    </script>
    <!--build:js-->
    <script src="../assets/js/vendors/jquery-3.5.1.min.js"></script>
    <script src="../assets/js/vendors/bootstrap.bundle.min.js"></script>
    <script src="../assets/js/vendors/bootstrap-slider.min.js"></script>
    <script src="../assets/js/vendors/jquery.countdown.min.js"></script>
    <script src="../assets/js/vendors/jquery.easing.min.js"></script>
    <script src="../assets/js/vendors/owl.carousel.min.js"></script>
    <script src="../assets/js/vendors/validator.min.js"></script>
    <script src="../assets/js/vendors/jquery.waypoints.min.js"></script>
    <script src="../assets/js/vendors/jquery.rcounterup.js"></script>
    <script src="../assets/js/vendors/magnific-popup.min.js"></script>
    <script src="../assets/js/vendors/hs.megamenu.js"></script>
    <script src="../assets/js/app.js"></script>
    <!--endbuild-->
</body>

</html>

</html>
